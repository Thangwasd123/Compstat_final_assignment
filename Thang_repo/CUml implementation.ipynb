{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6704b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "from cuml.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "# ... [previous data loading code] ...\n",
    "\n",
    "def manual_loocv_gpu_fast(predictors, data):\n",
    "    \"\"\"Optimized GPU LOOCV\"\"\"\n",
    "    n = len(data)\n",
    "    X = cp.array(data[list(predictors)].values, dtype=cp.float32)\n",
    "    y = cp.array(data['price_class'].values, dtype=cp.float32)\n",
    "    \n",
    "    predictions = cp.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Create masks for train/test\n",
    "        mask = cp.ones(n, dtype=bool)\n",
    "        mask[i] = False\n",
    "        \n",
    "        X_train = X[mask]\n",
    "        y_train = y[mask]\n",
    "        X_test = X[i:i+1]\n",
    "        \n",
    "        # GPU-accelerated logistic regression\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions[i] = model.predict_proba(X_test)[0, 1]\n",
    "    \n",
    "    # Calculate CV error on GPU\n",
    "    cv_error = float(cp.mean((y - predictions) ** 2))\n",
    "    \n",
    "    return cv_error\n",
    "\n",
    "# Parallel evaluation across models\n",
    "def evaluate_model(args):\n",
    "    i, predictors = args\n",
    "    cv_error = manual_loocv_gpu_fast(predictors, train)\n",
    "    return {\n",
    "        'model_id': i + 1,\n",
    "        'predictors': ', '.join(predictors),\n",
    "        'num_predictors': len(predictors),\n",
    "        'cv_error': cv_error\n",
    "    }\n",
    "\n",
    "print(\"Starting GPU-accelerated LOOCV...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel model evaluation\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    model_results = list(executor.map(evaluate_model, enumerate(all_models)))\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nTotal time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# ... [rest of results code] ...\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
